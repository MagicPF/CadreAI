# will use full version deepseek, use index book to orgnize the skill libirary, and RAG for inference

from http.client import responses
# import wandb
from ProteinExpert import ProteinExpert
from DrugExpert import DrugExpert
from BindingSimulator import BindingSimulator
from Commander import DeepSeekOllama, Deepseek_official
import sys
from utils import *
import warnings
import os
import json
from difflib import SequenceMatcher, get_close_matches
import random

warnings.filterwarnings("ignore")
sys.stdout.reconfigure(encoding='utf-8')


class DrugVoyager:
    def __init__(
        self,
        api_key="EMPTY",
        protein_server="http://search-protrek.com/",
        drug_model="OpenDFM/ChemDFM-v1.5-8B",
        drug_model_itself=None,
        commander_model="deepseek-r1:1.5b",
        use_msa_server=True,
        accelerator="gpu",
        device="cuda",
        max_iterations=5,
        skill_lib_file="skill_lib.json",
        history_log_file="history_logs.json",
        cache_dir="./jsons/",
        description="",
        need_save_each_step=False
    ):
        # wandb.init(
        #     project="DrugVoyager", name="drug_discovery_with_deepseek_commander",
        #     config={"device": device, "max_iterations": max_iterations}
        # )

        self.protein_expert = ProteinExpert(protein_server, cache_dir="./protein_DB/")
        if drug_model_itself is None:
            self.drug_expert = DrugExpert(
                model_name_or_id=drug_model,
                cache_file="drug_cache.json",
                need_cache=True,
                device=device,
                cache_dir=cache_dir
            )
        else:
            self.drug_expert = drug_model_itself

        self.binding_simulator = BindingSimulator(
            out_dir=cache_dir + f"/receptor{description}/",
            use_msa_server=use_msa_server,
            accelerator=accelerator,
            need_cache=False
        )
        # ä½¿ç”¨å®˜æ–¹ DeepSeek å®ä¾‹
        self.commander = Deepseek_official(key="sk-35965cbdd484474bb51cb8d30e6655c3", cache_dir=os.path.join(cache_dir, "jsons/"))
        self.max_iterations = max_iterations
        self.skill_lib_file = cache_dir + skill_lib_file
        self.history_log_file = cache_dir + history_log_file
        # æŠ€èƒ½åº“æ”¹ä¸ºæ ‡é¢˜->æ´è§åˆ—è¡¨çš„å­—å…¸
        self.skill_lib = self._load_skill_lib()
        self.history_logs = self._load_history_logs()
        self.shift_nochange_round = 5
        self.molecule_list = []

        # ===== æ–°å¢ï¼šé›†ä¸­ç®¡ç†ä¸Šé™ =====
        self.MAX_TITLES = 30            # æ¯æ¬¡ä¿å­˜ä»…ä¿ç•™ Top-30 æ ‡é¢˜
        self.MAX_TOTAL_SKILLS = 100     # å…¨åº“æ´è§æ€»é‡ä¸Šé™
        self.MAX_PER_TITLE = 5          # æ¯æ ‡é¢˜æœ€å¤šä¿ç•™ 5 æ¡ï¼ˆä½ åŸé€»è¾‘ï¼‰

    # ===== æ–°å¢ï¼šæ ‡é¢˜æ’åºï¼ˆæŒ‰æ´è§æ¡æ•°é™åºï¼ŒäºŒçº§é”®ç”¨æœ€è¿‘é•¿åº¦å’Œï¼Œä¿è¯ç¨³å®šæ€§ï¼‰=====
    def _rank_titles(self):
        def score(t):
            arr = self.skill_lib.get(t, [])
            # ä¸»æ’åºï¼šæ´è§æ•°é‡ï¼›è¾…æ’åºï¼šæœ€è¿‘ä¸¤æ¡é•¿åº¦å’Œï¼ˆåå‘æœ€è¿‘æœ‰æ›´æ–°çš„æ ‡é¢˜ï¼‰
            recent_two = arr[-2:] if len(arr) >= 2 else arr
            aux = sum(len(x) for x in recent_two)
            return (len(arr), aux)
        return sorted(self.skill_lib.keys(), key=score, reverse=True)

    # ===== æ–°å¢ï¼šå…¨åº“è£å‰ªï¼Œç¡®ä¿æ ‡é¢˜Top-30 & å…¨é‡â‰¤100 =====
    def _prune_skill_lib(self):
        # 1) æŒ‰æ ‡é¢˜Top-30ç­›é€‰
        keep_titles = set(self._rank_titles()[:self.MAX_TITLES])
        for t in list(self.skill_lib.keys()):
            if t not in keep_titles:
                del self.skill_lib[t]

        # 2) æ¯æ ‡é¢˜æœ€å¤šä¿ç•™ MAX_PER_TITLEï¼ˆä¿ç•™æœ€è¿‘çš„ï¼‰
        for t in list(self.skill_lib.keys()):
            self.skill_lib[t] = self.skill_lib[t][-self.MAX_PER_TITLE:]

        # 3) å…¨åº“æ€»é‡ â‰¤ MAX_TOTAL_SKILLSï¼ˆä¼˜å…ˆä¿ç•™æœ€è¿‘ï¼›ä»â€œå½“å‰æ´è§è¾ƒå¤šçš„æ ‡é¢˜â€çš„æœ€æ—§é¡¹å¼€å§‹ä¸¢å¼ƒï¼‰
        def total_count():
            return sum(len(v) for v in self.skill_lib.values())

        while total_count() > self.MAX_TOTAL_SKILLS and self.skill_lib:
            # æ‰¾å‡ºå½“å‰æ´è§æ•°æœ€å¤šçš„æ ‡é¢˜
            t = max(self.skill_lib.keys(), key=lambda k: len(self.skill_lib[k]))
            if not self.skill_lib[t]:
                del self.skill_lib[t]
                continue
            # ä¸¢å¼ƒè¯¥æ ‡é¢˜æœ€æ—§çš„ä¸€æ¡ï¼ˆåˆ—è¡¨å¤´éƒ¨ï¼‰ï¼Œä¿ç•™æœ€è¿‘
            self.skill_lib[t].pop(0)
            if len(self.skill_lib[t]) == 0:
                del self.skill_lib[t]

    def _merge_similar_titles(self):
        """
        åˆå¹¶ skill_lib ä¸­ç›¸ä¼¼çš„æ ‡é¢˜ï¼ˆkeyï¼‰ï¼Œå°†ç›¸ä¼¼æ ‡é¢˜ä¸‹çš„æ´è§åˆå¹¶åˆ°ä¸»æ ‡é¢˜ä¸‹ï¼Œåˆ é™¤å†—ä½™æ ‡é¢˜ã€‚
        ä¸¤æ ‡é¢˜ç›¸ä¼¼åº¦å¤§äº0.75 è§†ä¸ºç›¸ä¼¼ã€‚
        """
        titles = list(self.skill_lib.keys())
        merged = set()
        for title in titles:
            if title in merged:
                continue
            # æ‰¾åˆ°ä¸å½“å‰æ ‡é¢˜ç›¸ä¼¼çš„å…¶ä»–æ ‡é¢˜
            matches = get_close_matches(title, titles, n=len(titles), cutoff=0.5)
            for m in matches:
                if m != title and m in self.skill_lib:
                    # åˆå¹¶æ´è§åˆ—è¡¨
                    self.skill_lib[title].extend(self.skill_lib[m])
                    # æ ‡è®°å¹¶åˆ é™¤å†—ä½™æ ‡é¢˜
                    merged.add(m)
                    del self.skill_lib[m]
        # åˆå¹¶åå†å»é‡
        self._dedup_insights()

    # def _load_skill_lib(self):
        if os.path.exists(self.skill_lib_file):
            with open(self.skill_lib_file, "r", encoding="utf-8") as f:
                return json.load(f)
        return {}

    # ===== æ–°å¢ï¼šç»“æ„æ ¡éªŒï¼ˆæœ€å°ä¾µå…¥ï¼‰ =====
    def _is_valid_skill_lib(self, data):
        """
        è¦æ±‚ç»“æ„ä¸º {str: List[str]}ã€‚
        """
        if not isinstance(data, dict):
            return False
        for k, v in data.items():
            if not isinstance(k, str):
                return False
            if not isinstance(v, list):
                return False
            if not all(isinstance(x, str) for x in v):
                return False
        return True

    def _load_skill_lib(self):
        """
        è¯»å–æŠ€èƒ½åº“çš„è‡ªæ„ˆé€»è¾‘ï¼ˆä»…æœ€å°æ”¹åŠ¨ï¼‰ï¼š
        - æ­£å¸¸è¯»å–å¹¶è¿”å›ï¼›
        - è‹¥æŸåæˆ–ç»“æ„éæ³•ï¼šè‹¥å½“å‰å†…å­˜ä¸­æœ‰æœ€æ–°åˆæ³•ç‰ˆæœ¬ï¼ˆself.skill_libï¼‰ï¼Œç”¨å…¶è¦†ç›–æŸåæ–‡ä»¶ï¼›
          å¦åˆ™é‡ç½®ä¸º {} å¹¶å†™å›ã€‚
        """
        if os.path.exists(self.skill_lib_file):
            try:
                with open(self.skill_lib_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                if self._is_valid_skill_lib(data):
                    return data
                # ç»“æ„éæ³•ï¼Œèµ°è‡ªæ„ˆ
            except Exception:
                # JSONæŸåæˆ–è¯»å–å¼‚å¸¸ï¼Œèµ°è‡ªæ„ˆ
                pass

        # è‡ªæ„ˆï¼šä¼˜å…ˆç”¨å†…å­˜ä¸­æœ€æ–°åˆæ³•ç‰ˆæœ¬è¦†ç›–ï¼›å¦åˆ™é‡ç½®ä¸ºç©º
        if hasattr(self, "skill_lib") and self._is_valid_skill_lib(self.skill_lib) and self.skill_lib:
            healed = dict(self.skill_lib)
        else:
            healed = {}

        try:
            with open(self.skill_lib_file, "w", encoding="utf-8") as f:
                json.dump(healed, f, ensure_ascii=False, indent=4)
            print(f"âš ï¸ Skill library file corrupted or invalid. Auto-healed to valid state with {len(healed)} categories.")
        except Exception:
            # å†™å…¥å¼‚å¸¸åˆ™ä»è¿”å›å†…å­˜å¯¹è±¡ï¼Œé¿å…ä¸­æ–­
            pass

        return healed

    def _save_skill_lib(self):
        # å…ˆåˆå¹¶ç£ç›˜ä¸­å·²æœ‰çš„å†…å®¹
        existing = self._load_skill_lib()
        for title, insights in existing.items():
            if title in self.skill_lib:
                self.skill_lib[title].extend(insights)
            else:
                self.skill_lib[title] = insights

        # åˆå¹¶ç›¸ä¼¼æ ‡é¢˜ + å»é‡
        self._merge_similar_titles()
        self._dedup_insights()

        # === å…³é”®æ–°å¢ï¼šç»Ÿä¸€è£å‰ª ===
        self._prune_skill_lib()

        # æœ€ç»ˆè½ç›˜
        with open(self.skill_lib_file, "w", encoding="utf-8") as f:
            json.dump(self.skill_lib, f, ensure_ascii=False, indent=4)

    def _load_history_logs(self):
        if os.path.exists(self.history_log_file):
            with open(self.history_log_file, "r") as f:
                return json.load(f)
        return []
    
    def _dedup_insights(self):
        """
        å¯¹æ¯ä¸ªæ ‡é¢˜ä¸‹çš„æ´è§åˆ—è¡¨è¿›è¡Œå»é‡ï¼Œä¿ç•™é¦–æ¡å‡ºç°å†…å®¹ã€‚
        ä¸¤æ¡æ´è§ç›¸ä¼¼åº¦å¤§äº 0.4 è§†ä¸ºé‡å¤ã€‚
        """
        for title, insights in list(self.skill_lib.items()):
            unique = []
            for ins in insights:
                if not any(SequenceMatcher(None, ins, u).ratio() > 0.4 for u in unique):
                    unique.append(ins)
            self.skill_lib[title] = unique

    def _load_history_logs(self):
        if os.path.exists(self.history_log_file):
            with open(self.history_log_file, "r") as f:
                return json.load(f)
        return []

    def _save_history_logs(self):
        with open(self.history_log_file, "w") as f:
            json.dump(self.history_logs, f, indent=4)


    def analyze_results(self, target_protein, prev_property, current_property):
        cot_prompt = f"""
        - **Target Protein**: {target_protein}
        - **Molecular Optimization history**: {json.dumps(self.history_logs[-3:], indent=4)}
        - **Previous Property**: {prev_property}
        - **Current Property**: {current_property}
        """
        previous_knowledge = []
        for title, arr in self.skill_lib.items():
            for ins in arr:
                previous_knowledge.append(f"{title}: {ins}")
        prev_k_str = "\n".join(previous_knowledge)

        critique = self.commander.chat(
            cot_prompt,
            instruction=(
                "Analyze structural modifications on binding affinity and drug-like properties. "
                "Provide a constructive, self-contained insight understandable without background."
            )
        )
        title_c = self.commander.chat(
            critique,
            instruction="Generate a short title (3-5 words) summarizing this critique."
        ).strip()
        self.skill_lib.setdefault(title_c, []).append(critique)

        knowledge = self.commander.chat(
            f"Previous Knowledge:\n{prev_k_str}",
            instruction=(
                "Summarize key drug design insights or experience from past interactions in 20â€“30 words. "
                "Ensure the summary is constructive and self-contained."
            )
        )
        title_k = self.commander.chat(
            knowledge,
            instruction="Generate a short title (3-5 words) summarizing this knowledge."
        ).strip()
        self.skill_lib.setdefault(title_k, []).append(knowledge)

        insights = self.commander.chat(
            f"Critique: {critique}\nKnowledge: {knowledge}",
            instruction=(
                "Propose specific structural modifications for next-gen molecules in 20 words. "
                "Ensure suggestions are actionable and clear without extra context."
            )
        )
        intention = self.commander.chat(
            f"Prev: {prev_property}\nCurr: {current_property}\nInsights: {insights}\n",
            instruction="Inference next optimization intention in one concise, self-contained sentence:"
        )

        self._save_skill_lib()
        return insights, intention


    def retrive_knowledge(self, intention):
        # æ±‡æ€»å·²æœ‰ memory
        memory = [ins for insights in self.skill_lib.values() for ins in insights]
        if len(memory) > 0:
            # åˆ†æ­¥æ¨ç†ï¼šé€‰ç±»åˆ« -> é€‰æœ€ç›¸å…³æ´è§ -> æ‘˜è¦
            categories = list(self.skill_lib.keys())
            if intention:
                intention_prompt = f"Intention: {intention}. "
            else:
                intention_prompt = "" 
            selected_title = self.commander.chat(
                f"{intention_prompt} Available categories: {categories}",
                instruction="Select the most relevant category for next optimization. Return the exact title."
            )
            matched_titles = get_close_matches(selected_title, categories, n=1, cutoff=0.4)
            if matched_titles:
                selected_title = matched_titles[0]
            # from pdb import set_trace
            # set_trace()
            insights_list = self.skill_lib.get(selected_title, [])
            if len(insights_list) > 1:
                sample_size = max(1, int(len(insights_list) * 0.1))
                insights_list = random.sample(insights_list, sample_size)
            memory_summary = self.commander.chat(
                f"Insight: {insights_list}",
                instruction="Summarize the given insights into one concise sentence."
            )
            print(f"ğŸ“ Memory Summary: {memory_summary}\n")
        else:
            memory_summary = ""
        return memory_summary

    def run_drug_discovery_cycle(self, protein_sequence, protein_title="Unknown Protein", pdb_id="NotAvailable"):
        
        intention = ""
        print("ğŸ” Retrieving protein knowledge...")
        protein_knowledge = self.protein_expert.retrieval_interaction(protein_sequence)
        print(f"ğŸ“Œ Protein Interaction Data: {protein_knowledge}\n")
        # åˆå§‹ä¸‰ç»„å€™é€‰åˆ†å­ç”Ÿæˆï¼ˆé¦–æ¬¡æ—  memory æŒ‡å¼•ï¼‰
        candidates = []
        for i in range(8):
            prompt = self.commander.chat(
                f"Target Protein Info: {protein_knowledge} (Protein name: {protein_title})",
                instruction=(
                    "Suggest a small molecule scaffold. For target protein drug design."
                )
            )
            smiles = self.drug_expert.generate_molecule(f"Generate a drug for {protein_title}, the drug should: {prompt}")
            props = self.drug_expert.compute_properties(smiles)
            affinity = self.binding_simulator.CaculateAffinity(
                protein_sequence, smiles, pdb_id=pdb_id
            ).get('binding_affinity', 500.0)
            vina = float(affinity)
            qed = props.get('QuantitativeEstimateOfDruglikeness(â†‘)', 0.0)
            sa = props.get('NormalizedSyntheticAccessibilityScore(â†‘)', 0.0)
            composite = 0.5 * qed - 0.5 * vina + 0.4 * sa
            candidates.append((smiles, vina, qed, sa, composite))
            self.history_logs.append({
                "smiles": smiles,
                "vina": vina,
                "qed": qed,
                "sa": sa,
                "composite": composite
            })
        # from pdb import set_trace
        # set_trace()
        current_smiles, vina, qed, sa, composite = max(candidates, key=lambda x: x[4])
        print(f"ğŸ¯ Selected Best Initial Candidate: {current_smiles}\n")
        self.molecule_list.append([current_smiles, vina, qed, sa, composite])
        previous_metrics = {
            "binding_affinity": vina,
            "QuantitativeEstimateOfDruglikeness": qed,
            "NormalizedSyntheticAccessibilityScore": sa
        }
        current_metrics = previous_metrics

        # è¿­ä»£
        insights = None
        for iteration in range(1, self.max_iterations + 1):
            print(f"\nğŸš€ Iteration {iteration} begins...")
            memory_summary = self.retrive_knowledge(intention)
            candidate_round = []
            for i in range(3):
                # åœ¨ prompt ä¸­åŠ å…¥ memory_summary
                prompt = self.commander.chat(
                    (
                        f"Protein: {protein_knowledge}. Prev SMILES: {current_smiles}, Props: {current_metrics}. "
                        f"Insights summary :{memory_summary}."
                        f"Intention: {intention}."
                        f"Your Suggestion:"
                    ),
                    instruction=(
                        "Based on this summarized insights and knowledge, suggest structural modifications for optimization. "
                        "Focus on weight/substructure changes."
                    )
                )
                print(f"===work with : {pdb_id}===\n")
                smiles = self.drug_expert.generate_molecule(
                    f"Based on {current_smiles} and suggestions: {prompt}, generate SMILES"
                )
                props = self.drug_expert.compute_properties(smiles)
                # toxicity = self.drug_expert.compute_toxicity(smiles)
                
                affinity = self.binding_simulator.CaculateAffinity(
                    protein_sequence, smiles, pdb_id=pdb_id
                ).get('binding_affinity', 500.0)
                vina = float(affinity)
                qed = props.get('QuantitativeEstimateOfDruglikeness(â†‘)', 0.0)
                sa = props.get('NormalizedSyntheticAccessibilityScore(â†‘)', 0.0)
                composite = 0.5 * qed - 0.5 * vina + 0.4 * sa
                candidate_round.append((smiles, vina, qed, sa, composite))

            current_smiles, vina, qed, sa, composite = max(candidate_round, key=lambda x: x[4])
            current_metrics = {
                "binding_affinity": vina,
                "QuantitativeEstimateOfDruglikeness": qed,
                "NormalizedSyntheticAccessibilityScore": sa
            }
            self.history_logs.append({
                "smiles": smiles,
                "vina": vina,
                "qed": qed,
                "sa": sa,
                "composite": composite
            })
            print(f"ğŸ¯ Iteration {iteration} Winner: {current_smiles}\n")
            print(f"===work with : {pdb_id}===\n")
            self.molecule_list.append([current_smiles, vina, qed, sa, composite])
            insights, intention = self.analyze_results(
                target_protein=protein_title,
                prev_property=previous_metrics,
                current_property=current_metrics
            )
            print(f"ğŸ’¡ New Insight: {insights}\n")
            print(f"===work with : {pdb_id}===\n")
            previous_metrics =  current_metrics
        self._save_history_logs()
        print(f"\nâœ… Multi-iteration Molecule Evolution Logged! Total iterations: {len(self.molecule_list)}")
        return {"final_smiles": current_smiles, "molecule_list": self.molecule_list}


import tempfile

class DrugVoyagerPro:
    def __init__(
        self,
        api_key="EMPTY",
        protein_server="http://search-protrek.com/",
        drug_model="OpenDFM/ChemDFM-v1.5-8B",
        drug_model_itself=None,
        commander_model="deepseek-r1:1.5b",
        use_msa_server=True,
        accelerator="gpu",
        device="cuda",
        max_iterations=5,
        skill_lib_file="skill_lib.json",
        history_log_file="history_logs.json",
        cache_dir="./jsons/",
        description="",
        need_save_each_step=False
    ):
        # wandb.init(
        #     project="DrugVoyager", name="drug_discovery_with_deepseek_commander",
        #     config={"device": device, "max_iterations": max_iterations}
        # )

        os.makedirs(cache_dir, exist_ok=True)

        self.protein_expert = ProteinExpert(protein_server, cache_dir="./protein_DB/")
        if drug_model_itself is None:
            self.drug_expert = DrugExpert(
                model_name_or_id=drug_model,
                cache_file="drug_cache.json",
                need_cache=True,
                device=device,
                cache_dir=cache_dir
            )
        else:
            self.drug_expert = drug_model_itself

        self.binding_simulator = BindingSimulator(
            out_dir=cache_dir + f"/receptor{description}/",
            use_msa_server=use_msa_server,
            accelerator=accelerator,
            need_cache=False
        )
        # ä½¿ç”¨å®˜æ–¹ DeepSeek å®ä¾‹
        self.commander = Deepseek_official(key="sk-35965cbdd484474bb51cb8d30e6655c3",
                                           cache_dir=os.path.join(cache_dir, "jsons/"))
        self.max_iterations = max_iterations
        self.cache_dir = cache_dir
        self.skill_lib_file = os.path.join(cache_dir, skill_lib_file)
        self.history_log_file = os.path.join(cache_dir, history_log_file)
        self.molecules_csv_file = os.path.join(cache_dir, "molecules.csv")
        self.need_save_each_step = need_save_each_step

        # æŠ€èƒ½åº“æ”¹ä¸ºæ ‡é¢˜->æ´è§åˆ—è¡¨çš„å­—å…¸
        self.skill_lib = self._load_skill_lib()
        self.history_logs = self._load_history_logs()
        self.shift_nochange_round = 5
        self.molecule_list = []

        # ===== é›†ä¸­ç®¡ç†ä¸Šé™ =====
        self.MAX_TITLES = 30            # æ¯æ¬¡ä¿å­˜ä»…ä¿ç•™ Top-30 æ ‡é¢˜
        self.MAX_TOTAL_SKILLS = 100     # å…¨åº“æ´è§æ€»é‡ä¸Šé™
        self.MAX_PER_TITLE = 5          # æ¯æ ‡é¢˜æœ€å¤šä¿ç•™ 5 æ¡

        # åˆå§‹åŒ– CSV å¤´
        self._ensure_molecule_csv_header()

    # ---------- æŒä¹…åŒ–ä¸åŸå­å†™è¾…åŠ© ----------
    def _atomic_write_json(self, path: str, data_obj):
        """åŸå­å†™ JSONï¼šå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œå†æ›¿æ¢ç›®æ ‡æ–‡ä»¶ï¼Œé¿å…ä¸­é—´æ€æŸåã€‚"""
        dirpath = os.path.dirname(path) or "."
        os.makedirs(dirpath, exist_ok=True)
        with tempfile.NamedTemporaryFile("w", delete=False, dir=dirpath, suffix=".tmp", encoding="utf-8") as tf:
            json.dump(data_obj, tf, ensure_ascii=False, indent=4)
            tmp_name = tf.name
        os.replace(tmp_name, path)  # åŸå­æ›¿æ¢ï¼ˆåŒåˆ†åŒºï¼‰

    def _append_history(self, record: dict):
        """è¿½åŠ å†å²è®°å½•å¹¶ç«‹åˆ»è½ç›˜ï¼ˆåŸå­å†™ï¼‰ã€‚"""
        self.history_logs.append(record)
        # å³æ—¶è½ç›˜ï¼Œé˜²å´©æºƒä¸¢å¤±
        self._atomic_write_json(self.history_log_file, self.history_logs)

    def _ensure_molecule_csv_header(self):
        """ç¡®ä¿ molecules.csv æœ‰è¡¨å¤´ã€‚"""
        if not os.path.exists(self.molecules_csv_file):
            with open(self.molecules_csv_file, "w", encoding="utf-8") as f:
                f.write("SMILES,Vina,QED,SA,Composite\n")

    def _append_molecule_csv(self, smiles, vina, qed, sa, composite):
        """å³æ—¶æŠŠ winner è¿½åŠ åˆ° CSVï¼ˆé¿å…å´©æºƒä¸¢å¤±ï¼‰ã€‚"""
        with open(self.molecules_csv_file, "a", encoding="utf-8") as f:
            f.write(f"{smiles},{vina},{qed},{sa},{composite}\n")

    # ---------- æŠ€èƒ½åº“ ----------
    def _rank_titles(self):
        def score(t):
            arr = self.skill_lib.get(t, [])
            recent_two = arr[-2:] if len(arr) >= 2 else arr
            aux = sum(len(x) for x in recent_two)
            return (len(arr), aux)
        return sorted(self.skill_lib.keys(), key=score, reverse=True)

    def _prune_skill_lib(self):
        keep_titles = set(self._rank_titles()[:self.MAX_TITLES])
        for t in list(self.skill_lib.keys()):
            if t not in keep_titles:
                del self.skill_lib[t]
        for t in list(self.skill_lib.keys()):
            self.skill_lib[t] = self.skill_lib[t][-self.MAX_PER_TITLE:]

        def total_count():
            return sum(len(v) for v in self.skill_lib.values())

        while total_count() > self.MAX_TOTAL_SKILLS and self.skill_lib:
            t = max(self.skill_lib.keys(), key=lambda k: len(self.skill_lib[k]))
            if not self.skill_lib[t]:
                del self.skill_lib[t]
                continue
            self.skill_lib[t].pop(0)
            if len(self.skill_lib[t]) == 0:
                del self.skill_lib[t]

    def _merge_similar_titles(self):
        titles = list(self.skill_lib.keys())
        merged = set()
        for title in titles:
            if title in merged:
                continue
            matches = get_close_matches(title, titles, n=len(titles), cutoff=0.5)
            for m in matches:
                if m != title and m in self.skill_lib:
                    self.skill_lib[title].extend(self.skill_lib[m])
                    merged.add(m)
                    del self.skill_lib[m]
        self._dedup_insights()

    def _is_valid_skill_lib(self, data):
        if not isinstance(data, dict):
            return False
        for k, v in data.items():
            if not isinstance(k, str):
                return False
            if not isinstance(v, list):
                return False
            if not all(isinstance(x, str) for x in v):
                return False
        return True

    def _load_skill_lib(self):
        if os.path.exists(self.skill_lib_file):
            try:
                with open(self.skill_lib_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                if self._is_valid_skill_lib(data):
                    return data
            except Exception:
                pass
        # è‡ªæ„ˆï¼šç©ºåº“å†™å›
        healed = {}
        try:
            self._atomic_write_json(self.skill_lib_file, healed)
            print(f"âš ï¸ Skill library file corrupted or invalid. Auto-healed to valid state with 0 categories.")
        except Exception:
            pass
        return healed

    def _save_skill_lib(self):
        existing = self._load_skill_lib()
        for title, insights in existing.items():
            if title in self.skill_lib:
                self.skill_lib[title].extend(insights)
            else:
                self.skill_lib[title] = insights
        self._merge_similar_titles()
        self._dedup_insights()
        self._prune_skill_lib()
        self._atomic_write_json(self.skill_lib_file, self.skill_lib)

    def _load_history_logs(self):
        if os.path.exists(self.history_log_file):
            try:
                with open(self.history_log_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception:
                pass
        return []

    def _save_history_logs(self):
        # ä»ä¿ç•™è¯¥æ–¹æ³•ï¼ˆå…¼å®¹æ—§è°ƒç”¨ï¼‰ï¼Œä½†å®é™…æ¯æ¬¡ _append_history å·²å³æ—¶è½ç›˜
        self._atomic_write_json(self.history_log_file, self.history_logs)

    def _dedup_insights(self):
        for title, insights in list(self.skill_lib.items()):
            unique = []
            for ins in insights:
                if not any(SequenceMatcher(None, ins, u).ratio() > 0.4 for u in unique):
                    unique.append(ins)
            self.skill_lib[title] = unique

    # ---------- åˆ†æ/è®°å¿† ----------
    def analyze_results(self, target_protein, prev_property, current_property):
        cot_prompt = f"""
        - **Target Protein**: {target_protein}
        - **Molecular Optimization history**: {json.dumps(self.history_logs[-3:], indent=4)}
        - **Previous Property**: {prev_property}
        - **Current Property**: {current_property}
        """
        previous_knowledge = []
        for title, arr in self.skill_lib.items():
            for ins in arr:
                previous_knowledge.append(f"{title}: {ins}")
        prev_k_str = "\n".join(previous_knowledge)

        critique = self.commander.chat(
            cot_prompt,
            instruction=(
                "Analyze structural modifications on binding affinity and drug-like properties. "
                "Provide a constructive, self-contained insight understandable without background."
            )
        )
        title_c = self.commander.chat(
            critique,
            instruction="Generate a short title (3-5 words) summarizing this critique."
        ).strip()
        self.skill_lib.setdefault(title_c, []).append(critique)

        knowledge = self.commander.chat(
            f"Previous Knowledge:\n{prev_k_str}",
            instruction=(
                "Summarize key drug design insights or experience from past interactions in 20â€“30 words. "
                "Ensure the summary is constructive and self-contained."
            )
        )
        title_k = self.commander.chat(
            knowledge,
            instruction="Generate a short title (3-5 words) summarizing this knowledge."
        ).strip()
        self.skill_lib.setdefault(title_k, []).append(knowledge)

        insights = self.commander.chat(
            f"Critique: {critique}\nKnowledge: {knowledge}",
            instruction=(
                "Propose specific structural modifications for next-gen molecules in 20 words. "
                "Ensure suggestions are actionable and clear without extra context."
            )
        )
        intention = self.commander.chat(
            f"Prev: {prev_property}\nCurr: {current_property}\nInsights: {insights}\n",
            instruction="Inference next optimization intention in one concise, self-contained sentence:"
        )

        self._save_skill_lib()
        return insights, intention

    def retrive_knowledge(self, intention):
        memory = [ins for insights in self.skill_lib.values() for ins in insights]
        if len(memory) > 0:
            categories = list(self.skill_lib.keys())
            if intention:
                intention_prompt = f"Intention: {intention}. "
            else:
                intention_prompt = ""
            selected_title = self.commander.chat(
                f"{intention_prompt} Available categories: {categories}",
                instruction="Select the most relevant category for next optimization. Return the exact title."
            )
            matched_titles = get_close_matches(selected_title, categories, n=1, cutoff=0.4)
            if matched_titles:
                selected_title = matched_titles[0]
            insights_list = self.skill_lib.get(selected_title, [])
            if len(insights_list) > 1:
                sample_size = max(1, int(len(insights_list) * 0.1))
                insights_list = random.sample(insights_list, sample_size)
            memory_summary = self.commander.chat(
                f"Insight: {insights_list}",
                instruction="Summarize the given insights into one concise sentence."
            )
            print(f"ğŸ“ Memory Summary: {memory_summary}\n")
        else:
            memory_summary = ""
        return memory_summary

    # ---------- ä¸»æµç¨‹ ----------
    def _maybe_record_molecule(self, smiles, vina, qed, sa, composite, force: bool = False):
        """æŒ‰å¼€å…³è®°å½•åˆ°å†…å­˜ï¼Œå¹¶åœ¨éœ€è¦æ—¶å³æ—¶å†™å…¥ CSVã€‚"""
        if self.need_save_each_step or force:
            self.molecule_list.append([smiles, vina, qed, sa, composite])
            self._append_molecule_csv(smiles, vina, qed, sa, composite)

    def run_drug_discovery_cycle(self, protein_sequence, protein_title="Unknown Protein", pdb_id="NotAvailable"):
        intention = ""
        print("ğŸ” Retrieving protein knowledge...")
        protein_knowledge = self.protein_expert.retrieval_interaction(protein_sequence)
        print(f"ğŸ“Œ Protein Interaction Data: {protein_knowledge}\n")

        # åˆå§‹å€™é€‰ç”Ÿæˆ
        candidates = []
        for i in range(8):
            prompt = self.commander.chat(
                f"Target Protein Info: {protein_knowledge} (Protein name: {protein_title})",
                instruction=("Suggest a small molecule scaffold. For target protein drug design.")
            )
            smiles = self.drug_expert.generate_molecule(
                f"Generate a drug for {protein_title}, the drug should: {prompt}"
            )
            props = self.drug_expert.compute_properties(smiles)
            affinity = self.binding_simulator.CaculateAffinity(
                protein_sequence, smiles, pdb_id=pdb_id
            ).get('binding_affinity', 500.0)
            vina = float(affinity)
            qed = props.get('QuantitativeEstimateOfDruglikeness(â†‘)', 0.0)
            sa = props.get('NormalizedSyntheticAccessibilityScore(â†‘)', 0.0)
            composite = 0.5 * qed - 0.5 * vina + 0.4 * sa

            candidates.append((smiles, vina, qed, sa, composite))
            # å†å²æ—¥å¿—ï¼šç«‹å³è½ç›˜
            self._append_history({
                "stage": "init",
                "smiles": smiles, "vina": vina, "qed": qed, "sa": sa, "composite": composite
            })

        # åˆå§‹æœ€ä½³
        current_smiles, vina, qed, sa, composite = max(candidates, key=lambda x: x[4])
        print(f"ğŸ¯ Selected Best Initial Candidate: {current_smiles}\n")
        # å¯é€‰ï¼šè®°å½•åˆå§‹æœ€ä½³åˆ° CSV
        self._maybe_record_molecule(current_smiles, vina, qed, sa, composite, force=False)

        previous_metrics = {
            "binding_affinity": vina,
            "QuantitativeEstimateOfDruglikeness": qed,
            "NormalizedSyntheticAccessibilityScore": sa
        }
        current_metrics = dict(previous_metrics)

        # è¿­ä»£
        insights = None
        for iteration in range(1, self.max_iterations + 1):
            print(f"\nğŸš€ Iteration {iteration} begins...")
            memory_summary = self.retrive_knowledge(intention)
            candidate_round = []
            for i in range(3):
                prompt = self.commander.chat(
                    (f"Protein: {protein_knowledge}. Prev SMILES: {current_smiles}, Props: {current_metrics}. "
                     f"Insights summary :{memory_summary}. Intention: {intention}. Your Suggestion:"),
                    instruction=("Based on this summarized insights and knowledge, suggest structural modifications for optimization. "
                                 "Focus on weight/substructure changes.")
                )
                print(f"===work with : {pdb_id}===\n")
                smi_i = self.drug_expert.generate_molecule(
                    f"Based on {current_smiles} and suggestions: {prompt}, generate SMILES"
                )
                props_i = self.drug_expert.compute_properties(smi_i)
                affinity_i = self.binding_simulator.CaculateAffinity(
                    protein_sequence, smi_i, pdb_id=pdb_id
                ).get('binding_affinity', 500.0)
                vina_i = float(affinity_i)
                qed_i = props_i.get('QuantitativeEstimateOfDruglikeness(â†‘)', 0.0)
                sa_i = props_i.get('NormalizedSyntheticAccessibilityScore(â†‘)', 0.0)
                comp_i = 0.5 * qed_i - 0.5 * vina_i + 0.4 * sa_i
                candidate_round.append((smi_i, vina_i, qed_i, sa_i, comp_i))

            # æœ¬è½® winner
            winner = max(candidate_round, key=lambda x: x[4])
            current_smiles, vina, qed, sa, composite = winner
            current_metrics = {
                "binding_affinity": vina,
                "QuantitativeEstimateOfDruglikeness": qed,
                "NormalizedSyntheticAccessibilityScore": sa
            }

            # å†å²æ—¥å¿—ï¼šç«‹å³è½ç›˜
            self._append_history({
                "stage": f"iter_{iteration}",
                "smiles": current_smiles, "vina": vina, "qed": qed, "sa": sa, "composite": composite
            })

            print(f"ğŸ¯ Iteration {iteration} Winner: {current_smiles}\n")
            print(f"===work with : {pdb_id}===\n")

            # winner å³æ—¶å†™ CSVï¼ˆå— need_save_each_step æ§åˆ¶ï¼‰
            self._maybe_record_molecule(current_smiles, vina, qed, sa, composite, force=False)

            insights, intention = self.analyze_results(
                target_protein=protein_title,
                prev_property=previous_metrics,
                current_property=current_metrics
            )
            print(f"ğŸ’¡ New Insight: {insights}\n")
            print(f"===work with : {pdb_id}===\n")
            previous_metrics = current_metrics

        # æœ€ç»ˆåˆ†å­ï¼šç¡®ä¿å†™å…¥ CSVï¼ˆå³ä½¿ need_save_each_step=Falseï¼‰
        self._maybe_record_molecule(current_smiles, vina, qed, sa, composite, force=True)

        # å†æ¬¡å†—ä½™ä¿å­˜ä¸€æ¬¡å†å²ï¼ˆå¤šä¸€å±‚ä¿é™©ï¼‰
        self._save_history_logs()

        print(f"\nâœ… Multi-iteration Molecule Evolution Logged! Total iterations: {len(self.molecule_list)}")
        return {"final_smiles": current_smiles, "molecule_list": self.molecule_list}